{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "handle is closed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2c2ceb2a5f13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/oles/src/Banana_Linux/Banana.x86_64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_name, worker_id, base_port, curriculum, seed, docker_training, no_graphics)\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0maca_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_academy_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl_init_parameters_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnityTimeOutException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36msend_academy_parameters\u001b[0;34m(self, init_parameters)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap_unity_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnityRLInput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnityOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;34m\"You may need to manually close a previously opened environment \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \"or use a different worker number.\".format(str(self.worker_id)))\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             raise UnityTimeOutException(\n\u001b[1;32m     60\u001b[0m                 \u001b[0;34m\"The Unity environment took too long to respond. Make sure that :\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;34m\"\"\"Whether there is any input available to be read\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_check_closed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"handle is closed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: handle is closed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception calling application: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/drlnd/lib/python3.6/site-packages/grpc/_server.py\", line 385, in _call_behavior\n",
      "    return behavior(argument, context), True\n",
      "  File \"/opt/miniconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\", line 25, in Exchange\n",
      "    self.child_conn.send(request)\n",
      "  File \"/opt/miniconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/opt/miniconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/miniconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"/home/oles/src/Banana_Linux/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnityEnvironmentException",
     "evalue": "No Unity environment is loaded.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityEnvironmentException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c6aa12bad02b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reset the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# number of agents in the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of agents:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, train_mode, config, lesson)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mUnityEnvironmentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No Unity environment is loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvector_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAllBrainInfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnityEnvironmentException\u001b[0m: No Unity environment is loaded."
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnityEnvironmentException",
     "evalue": "No Unity environment is loaded.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityEnvironmentException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1baceacf4cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mUnityEnvironmentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No Unity environment is loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnityEnvironmentException\u001b[0m: No Unity environment is loaded."
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name=\"/home/oles/src/Banana_Linux/Banana.x86_64\")\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'state_size', 'action_size', and 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5a07d755db99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'state_size', 'action_size', and 'seed'"
     ]
    }
   ],
   "source": [
    "from model import QNetwork\n",
    "\n",
    "m = QNetwork(state_size)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.4366,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.1940,  1.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.4786,  0.0000,  0.0000,  1.0000,  0.0000,  0.5211,  0.0000,\n",
       "          0.0000,  1.0000,  0.0000,  0.3829,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.1041,  1.0000,  0.0000,  0.0000,  0.0000,  0.3715,\n",
       "          0.0000,  0.0000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.from_numpy(state).float().unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "\n",
    "agent = Agent(state_size=state_size, action_size=action_size, seed=0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-9bd55e4072e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# watch an untrained agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, train_mode, config, lesson)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             outputs = self.communicator.exchange(\n\u001b[0;32m--> 261\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_reset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m             )\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36mexchange\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "# watch an untrained agent\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "state = env_info.vector_observations[0]\n",
    "score = 0\n",
    "for j in range(300):\n",
    "    action = agent.act(state)                      # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "#     time.sleep(0.5)\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 199, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, j, action_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20\tAverage Score: -0.40learning took  18.798656940460205\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def dqn(n_episodes=20, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995, solved_score=13):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state = env_info.vector_observations[0]\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)                 # select an action\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=200.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "start = time.time()\n",
    "scores = dqn()\n",
    "learning_took = time.time() - start\n",
    "\n",
    "print(\"learning took \", learning_took)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dqn_agent\n",
    "\n",
    "dqn_agent.device[0] = torch.device(\"cpu\")\n",
    "agent = dqn_agent.Agent(state_size=state_size, action_size=action_size, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
